{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `duckreg`: Out-of-memory regressions with `duckdb`\n",
    "\n",
    "Remember to carefully examine the underlying queries that generate the data; the package merely passes it into `np.linalg.lstsq` to solve the least squares problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"cp47Ni\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.4.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"cp47Ni\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"cp47Ni\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"diXAkH\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.4.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"diXAkH\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"diXAkH\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sectional Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "def generate_sample_data(N=10_000_000, seed=12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    X = rng.choice(range(20), (N, 2), True)\n",
    "    Y = D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    Y2 = -1 * D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, Y2, D, X], axis=1), columns=[\"Y\", \"Y2\", \"D\", \"f1\", \"f2\"]\n",
    "    ).assign(rowid=range(N))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create and populate DuckDB database\n",
    "def create_duckdb_database(df, db_name=\"large_dataset.db\", table=\"data\"):\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DuckDB database: large_dataset.db\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "df = generate_sample_data()\n",
    "db_name = 'large_dataset.db'\n",
    "create_duckdb_database(df, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dataset. This dataset could be unreasonably large, which prevents the use of conventional in-memory regression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.226866</td>\n",
       "      <td>24.444717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.088713</td>\n",
       "      <td>35.392007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.472292</td>\n",
       "      <td>21.185366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.842856</td>\n",
       "      <td>38.012720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.136978</td>\n",
       "      <td>22.168634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y         Y2    D    f1    f2  rowid\n",
       "0  27.226866  24.444717  1.0  16.0   5.0      0\n",
       "1  35.088713  35.392007  0.0   1.0  17.0      1\n",
       "2  22.472292  21.185366  1.0   6.0   8.0      2\n",
       "3  39.842856  38.012720  0.0   9.0  15.0      3\n",
       "4  23.136978  22.168634  0.0  10.0   6.0      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = 'large_dataset.db'\n",
    "conn = duckdb.connect(db_name)\n",
    "query = \"SELECT * FROM data limit 5\"\n",
    "conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "$$\n",
    "Y_i + X_i \\beta + \\alpha_i + \\epsilon_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:17<00:00, 13.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000584\n",
       "1        0.999347        0.000726\n",
       "2        1.000035        0.000042\n",
       "3        2.000067        0.000038"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `DuckRegression` class, you can choose to run the model fits via the `pyfixest` package, in which case \n",
    "the `DuckRegression.fit()` will return a `pyfixest` model object and is therefore compatible with the `pyfixest` API (tables, visualisers etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:17<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     est1                    est2\n",
      "------------  ---------------------------  ----------------------\n",
      "depvar                             mean_Y                       Y\n",
      "-----------------------------------------------------------------\n",
      "Intercept     -0.000274*** (8e-06.000000)\n",
      "D              0.999347*** (6e-06.000000)  0.999347*** (0.000941)\n",
      "f1             1.000035*** (1e-06.000000)\n",
      "f2             2.000067*** (1e-06.000000)\n",
      "-----------------------------------------------------------------\n",
      "f2                                      -                       x\n",
      "f1                                      -                       x\n",
      "-----------------------------------------------------------------\n",
      "R2                                      -                0.994031\n",
      "S.E. type                             iid                  by: f1\n",
      "Observations                     10000000                10000000\n",
      "-----------------------------------------------------------------\n",
      "Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n",
      "Format of coefficient cell:\n",
      "Coefficient (Std. Error)\n"
     ]
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232,\n",
    "    fitter = \"feols\"\n",
    ")\n",
    "duckreg_fit = m.fit()\n",
    "\n",
    "feols_fit = pf.feols(\"Y ~ D | f1 + f2\", data = df)\n",
    "pf.etable([duckreg_fit, feols_fit], digits = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run regressions on multiple outcome variables painlessly since we only need to keep track of summary stats; just include all dependent variables on the RHS of the formula. The output of `DuckRegression.fit()` concatenates the results of all regressions into a single table, which can then be sliced to extract the relevant coefficients and SEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:19<00:00, 11.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'point_estimate': array([-2.73682294e-04, -4.39868205e-04,  9.99347122e-01, -9.99443294e-01,\n",
       "         1.00003536e+00,  1.00006450e+00,  2.00006685e+00,  1.99995671e+00]),\n",
       " 'standard_error': array([5.84076302e-04, 4.07910209e-04, 7.26039675e-04, 4.50210091e-04,\n",
       "        4.21583266e-05, 4.98886252e-05, 3.83873471e-05, 3.42657953e-05])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y + Y2 ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232\n",
    ")\n",
    "\n",
    "m2.fit()\n",
    "results = m2.summary()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed data contains summary stats on all outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y2</th>\n",
       "      <th>mean_Y</th>\n",
       "      <th>mean_Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12411</td>\n",
       "      <td>459065.694057</td>\n",
       "      <td>459270.896783</td>\n",
       "      <td>36.988614</td>\n",
       "      <td>37.005148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12661</td>\n",
       "      <td>392740.854101</td>\n",
       "      <td>367220.904425</td>\n",
       "      <td>31.019734</td>\n",
       "      <td>29.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12501</td>\n",
       "      <td>600201.437827</td>\n",
       "      <td>575122.265422</td>\n",
       "      <td>48.012274</td>\n",
       "      <td>46.006101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12573</td>\n",
       "      <td>301720.779509</td>\n",
       "      <td>301755.610058</td>\n",
       "      <td>23.997517</td>\n",
       "      <td>24.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12673</td>\n",
       "      <td>152088.158554</td>\n",
       "      <td>151964.223638</td>\n",
       "      <td>12.000959</td>\n",
       "      <td>11.991180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12351</td>\n",
       "      <td>123590.382735</td>\n",
       "      <td>98804.339196</td>\n",
       "      <td>10.006508</td>\n",
       "      <td>7.999704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12525</td>\n",
       "      <td>626251.072596</td>\n",
       "      <td>601282.490217</td>\n",
       "      <td>50.000086</td>\n",
       "      <td>48.006586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12493</td>\n",
       "      <td>149787.607136</td>\n",
       "      <td>149961.557496</td>\n",
       "      <td>11.989723</td>\n",
       "      <td>12.003647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12589</td>\n",
       "      <td>264529.170235</td>\n",
       "      <td>239289.241863</td>\n",
       "      <td>21.012723</td>\n",
       "      <td>19.007804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12537</td>\n",
       "      <td>501361.349053</td>\n",
       "      <td>476438.726759</td>\n",
       "      <td>39.990536</td>\n",
       "      <td>38.002610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       D    f1    f2  count          sum_Y         sum_Y2     mean_Y  \\\n",
       "0    0.0  15.0  11.0  12411  459065.694057  459270.896783  36.988614   \n",
       "1    1.0  12.0   9.0  12661  392740.854101  367220.904425  31.019734   \n",
       "2    1.0   9.0  19.0  12501  600201.437827  575122.265422  48.012274   \n",
       "3    0.0  18.0   3.0  12573  301720.779509  301755.610058  23.997517   \n",
       "4    0.0   6.0   3.0  12673  152088.158554  151964.223638  12.000959   \n",
       "..   ...   ...   ...    ...            ...            ...        ...   \n",
       "795  1.0   9.0   0.0  12351  123590.382735   98804.339196  10.006508   \n",
       "796  1.0  15.0  17.0  12525  626251.072596  601282.490217  50.000086   \n",
       "797  0.0   0.0   6.0  12493  149787.607136  149961.557496  11.989723   \n",
       "798  1.0   8.0   6.0  12589  264529.170235  239289.241863  21.012723   \n",
       "799  1.0  17.0  11.0  12537  501361.349053  476438.726759  39.990536   \n",
       "\n",
       "       mean_Y2  \n",
       "0    37.005148  \n",
       "1    29.004100  \n",
       "2    46.006101  \n",
       "3    24.000287  \n",
       "4    11.991180  \n",
       "..         ...  \n",
       "795   7.999704  \n",
       "796  48.006586  \n",
       "797  12.003647  \n",
       "798  19.007804  \n",
       "799  38.002610  \n",
       "\n",
       "[800 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.df_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept_Y</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept_Y2</th>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y2</th>\n",
       "      <td>-0.999443</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y2</th>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y2</th>\n",
       "      <td>1.999957</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              point_estimate  standard_error\n",
       "Intercept_Y        -0.000274        0.000584\n",
       "Intercept_Y2       -0.000440        0.000408\n",
       "D_Y                 0.999347        0.000726\n",
       "D_Y2               -0.999443        0.000450\n",
       "f1_Y                1.000035        0.000042\n",
       "f1_Y2               1.000064        0.000050\n",
       "f2_Y                2.000067        0.000038\n",
       "f2_Y2               1.999957        0.000034"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    "    index = [f\"{x}_{y}\" for x in ['Intercept', \"D\", \"f1\", \"f2\"] for y in ['Y', 'Y2']]\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_panel(\n",
    "    # Parameters\n",
    "    N=1_000_000,\n",
    "    T=35,  # Number of units and time periods\n",
    "    T0=5,  # Treatment starts at T0\n",
    "    tau=0.005,\n",
    "    sigma_list=[5, 2, 0.01, 2],\n",
    "    seed=42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    sigma_unit, sigma_time, sigma_tt, sigma_e = sigma_list\n",
    "    # Generate data\n",
    "    unit_ids = np.repeat(np.arange(N), T)\n",
    "    time_ids = np.tile(np.arange(T), N)\n",
    "\n",
    "    # Generate unit-specific intercepts and time trends\n",
    "    unit_fe = np.random.normal(0, sigma_unit, N)\n",
    "    time_fe = np.random.normal(\n",
    "        0, sigma_time, T\n",
    "    )  # Common shocks for all units at each time period\n",
    "    unit_tt = np.random.normal(0, sigma_tt, N)\n",
    "\n",
    "    # Generate treatment indicator (randomly assigned)\n",
    "    W = np.random.binomial(1, 0.5, N)\n",
    "    W = np.repeat(W, T)\n",
    "    W = W * (time_ids >= T0)\n",
    "\n",
    "    rho = 0.7  # Autoregressive parameter for residuals\n",
    "    # Generate serially correlated residuals for each unit (optimized version)\n",
    "    residuals = np.zeros((N, T))\n",
    "    residuals[:, 0] = np.random.normal(0, sigma_e, N)\n",
    "    epsilon = np.random.normal(0, 1, (N, T - 1))\n",
    "    factor = 0.5 * np.sqrt(1 - rho**2)\n",
    "    for t in range(1, T):\n",
    "        residuals[:, t] = rho * residuals[:, t - 1] + factor * epsilon[:, t - 1]\n",
    "    # iid\n",
    "    # residuals = np.random.normal(0, 0.5, N*T)\n",
    "\n",
    "    # Generate outcome\n",
    "    Y = (\n",
    "        np.repeat(unit_fe, T)\n",
    "        + np.repeat(unit_tt, T) * time_ids\n",
    "        + tau * W  # Treatment effect is 1\n",
    "        + np.tile(time_fe, N)  # time FE\n",
    "        + residuals.flatten()\n",
    "    )  # Individual noise\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"unit\": unit_ids, \"time\": time_ids, \"Y\": Y, \"W\": W})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = sim_panel(tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name, table_name = \"panel_data.db\", \"panel_data\"\n",
    "# write to database\n",
    "conn = duckdb.connect(db_name)\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.execute(f\"CREATE TABLE {table_name} AS SELECT * from df\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit  time         Y  W\n",
      "0     0     0  3.096240  0\n",
      "1     0     1  2.656935  0\n",
      "2     0     2  5.084101  0\n",
      "3     0     3  3.274999  0\n",
      "4     0     4  4.638763  0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect(db_name)\n",
    "print(conn.execute(\"SELECT * FROM panel_data LIMIT 5\").fetchdf())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckreg.estimators import DuckMundlak, DuckDoubleDemeaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundlak\n",
    "\n",
    "\n",
    "One-way mundlak \n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "Two-way mundlak\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i, \\cdot} + \\delta \\bar{X}_{\\cdot, t} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "both of which can be compressed easily with `duckdb`.\n",
    "\n",
    "These representations are much more efficient than the above general procedure because the unit and time fixed effects are typically very high dimensional, but covariate averages are not. Also see [Arkhangelsky and Imbens](https://arxiv.org/abs/1807.02099) on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:45<00:00,  5.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.413955</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.896134        0.005633\n",
       "1        1.003877        0.001765\n",
       "2        0.009106        0.009642\n",
       "3       -2.413955        0.002209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mundlak = DuckMundlak(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    covariates=[\"W\"],\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=50,\n",
    "    seed = 929\n",
    ")\n",
    "mundlak.fit()\n",
    "\n",
    "mundlak_results = mundlak.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[mundlak_results[\"point_estimate\"], mundlak_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powered by the following sequence of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE unit_avgs AS\n",
      "        SELECT unit,\n",
      "               AVG(W) AS avg_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "            CREATE TEMP TABLE time_avgs AS\n",
      "            SELECT time,\n",
      "                   AVG(W) AS avg_W_time\n",
      "            FROM panel_data\n",
      "            GROUP BY time\n",
      "            \n",
      "\n",
      "        CREATE TEMP TABLE design_matrix AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W,\n",
      "            u.avg_W_unit\n",
      "            , tm.avg_W_time\n",
      "        FROM panel_data t\n",
      "        JOIN unit_avgs u ON t.unit = u.unit\n",
      "        JOIN time_avgs tm ON t.time = tm.time\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            W,\n",
      "            avg_W_unit\n",
      "            , avg_W_time,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM design_matrix\n",
      "        GROUP BY W,\n",
      "                    avg_W_unit\n",
      "                    , avg_W_time\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                W,\n",
      "                avg_W_unit\n",
      "                , avg_W_time,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM design_matrix\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY W,\n",
      "                        avg_W_unit\n",
      "                        , avg_W_time\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(mundlak.unit_avg_query)\n",
    "print(mundlak.time_avg_query)\n",
    "print(mundlak.design_matrix_query)\n",
    "print(mundlak.compress_query)\n",
    "print(mundlak.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Demeaning\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\ddot{X}_{it} \\beta + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\ddot{X}_{it} = X_{it} - \\bar{X}_{i, \\cdot} - \\bar{X}_{\\cdot, t} + \\bar{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:14<00:00,  6.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.295524        0.003857\n",
       "1        1.003877        0.002097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_demean = DuckDoubleDemeaning(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    treatment_var=\"W\",\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 828\n",
    ")\n",
    "\n",
    "double_demean.fit()\n",
    "\n",
    "dd_results = double_demean.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[dd_results[\"point_estimate\"], dd_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE overall_mean AS\n",
      "        SELECT AVG(W) AS mean_W\n",
      "        FROM panel_data\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE unit_means AS\n",
      "        SELECT unit, AVG(W) AS mean_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE time_means AS\n",
      "        SELECT time, AVG(W) AS mean_W_time\n",
      "        FROM panel_data\n",
      "        GROUP BY time\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE double_demeaned AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W - um.mean_W_unit - tm.mean_W_time + om.mean_W AS ddot_W\n",
      "        FROM panel_data t\n",
      "        JOIN unit_means um ON t.unit = um.unit\n",
      "        JOIN time_means tm ON t.time = tm.time\n",
      "        CROSS JOIN overall_mean om\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            ddot_W,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM double_demeaned\n",
      "        GROUP BY ddot_W\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                ddot_W,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM double_demeaned\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY ddot_W\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(double_demean.overall_mean_query)\n",
    "print(double_demean.unit_mean_query)\n",
    "print(double_demean.time_mean_query)\n",
    "print(double_demean.double_demean_query)\n",
    "print(double_demean.compress_query)\n",
    "print(double_demean.bootstrap_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfixest-pKOwcWPT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
