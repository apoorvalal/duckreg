{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `duckreg`: Out-of-memory regressions with `duckdb`\n",
    "\n",
    "Carefully examine the underlying queries that generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-sectional Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "def generate_sample_data(N=10_000_000, seed=12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    X = rng.choice(range(20), (N, 2), True)\n",
    "    Y = D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    Y2 = -1 * D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, Y2, D, X], axis=1), columns=[\"Y\", \"Y2\", \"D\", \"f1\", \"f2\"]\n",
    "    ).assign(rowid=range(N))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create and populate DuckDB database\n",
    "def create_duckdb_database(df, db_name=\"large_dataset.db\", table=\"data\"):\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DuckDB database: large_dataset.db\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "df = generate_sample_data()\n",
    "db_name = 'large_dataset.db'\n",
    "create_duckdb_database(df, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.226866</td>\n",
       "      <td>24.444717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.088713</td>\n",
       "      <td>35.392007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.472292</td>\n",
       "      <td>21.185366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.842856</td>\n",
       "      <td>38.012720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.136978</td>\n",
       "      <td>22.168634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y         Y2    D    f1    f2  rowid\n",
       "0  27.226866  24.444717  1.0  16.0   5.0      0\n",
       "1  35.088713  35.392007  0.0   1.0  17.0      1\n",
       "2  22.472292  21.185366  1.0   6.0   8.0      2\n",
       "3  39.842856  38.012720  0.0   9.0  15.0      3\n",
       "4  23.136978  22.168634  0.0  10.0   6.0      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = 'large_dataset.db'\n",
    "conn = duckdb.connect(db_name)\n",
    "query = \"SELECT * FROM data limit 5\"\n",
    "conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "$$\n",
    "Y_i + X_i \\beta + \\alpha_i + \\epsilon_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000670\n",
       "1        0.999347        0.000727\n",
       "2        1.000035        0.000047\n",
       "3        2.000067        0.000040"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `DuckRegression` class, you can choose to run the model fits via the `pyfixest` package, in which case \n",
    "the `DuckRegression.fit()` will return a `pyfixest` model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     est1                    est2\n",
      "------------  ---------------------------  ----------------------\n",
      "depvar                             mean_Y                       Y\n",
      "-----------------------------------------------------------------\n",
      "Intercept     -0.000274*** (8e-06.000000)\n",
      "D              0.999347*** (6e-06.000000)  0.999347*** (0.000941)\n",
      "f1             1.000035*** (1e-06.000000)\n",
      "f2             2.000067*** (1e-06.000000)\n",
      "-----------------------------------------------------------------\n",
      "f1                                      -                       x\n",
      "f2                                      -                       x\n",
      "-----------------------------------------------------------------\n",
      "R2                                      -                0.994031\n",
      "S.E. type                    NP Bootstrap                  by: f1\n",
      "Observations                     10000000                10000000\n",
      "-----------------------------------------------------------------\n",
      "Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n",
      "Format of coefficient cell:\n",
      "Coefficient (Std. Error)\n"
     ]
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232,\n",
    "    fitter = \"feols\"\n",
    ")\n",
    "duckreg_fit = m.fit()\n",
    "\n",
    "feols_fit = pf.feols(\"Y ~ D | f1 + f2\", data = df)\n",
    "pf.etable([duckreg_fit, feols_fit], digits = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_panel(\n",
    "    # Parameters\n",
    "    N=1_000_000,\n",
    "    T=35,  # Number of units and time periods\n",
    "    T0=5,  # Treatment starts at T0\n",
    "    tau=0.005,\n",
    "    sigma_list=[5, 2, 0.01, 2],\n",
    "    seed=42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    sigma_unit, sigma_time, sigma_tt, sigma_e = sigma_list\n",
    "    # Generate data\n",
    "    unit_ids = np.repeat(np.arange(N), T)\n",
    "    time_ids = np.tile(np.arange(T), N)\n",
    "\n",
    "    # Generate unit-specific intercepts and time trends\n",
    "    unit_fe = np.random.normal(0, sigma_unit, N)\n",
    "    time_fe = np.random.normal(\n",
    "        0, sigma_time, T\n",
    "    )  # Common shocks for all units at each time period\n",
    "    unit_tt = np.random.normal(0, sigma_tt, N)\n",
    "\n",
    "    # Generate treatment indicator (randomly assigned)\n",
    "    W = np.random.binomial(1, 0.5, N)\n",
    "    W = np.repeat(W, T)\n",
    "    W = W * (time_ids >= T0)\n",
    "\n",
    "    rho = 0.7  # Autoregressive parameter for residuals\n",
    "    # Generate serially correlated residuals for each unit (optimized version)\n",
    "    residuals = np.zeros((N, T))\n",
    "    residuals[:, 0] = np.random.normal(0, sigma_e, N)\n",
    "    epsilon = np.random.normal(0, 1, (N, T - 1))\n",
    "    factor = 0.5 * np.sqrt(1 - rho**2)\n",
    "    for t in range(1, T):\n",
    "        residuals[:, t] = rho * residuals[:, t - 1] + factor * epsilon[:, t - 1]\n",
    "    # iid\n",
    "    # residuals = np.random.normal(0, 0.5, N*T)\n",
    "\n",
    "    # Generate outcome\n",
    "    Y = (\n",
    "        np.repeat(unit_fe, T)\n",
    "        + np.repeat(unit_tt, T) * time_ids\n",
    "        + tau * W  # Treatment effect is 1\n",
    "        + np.tile(time_fe, N)  # time FE\n",
    "        + residuals.flatten()\n",
    "    )  # Individual noise\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"unit\": unit_ids, \"time\": time_ids, \"Y\": Y, \"W\": W})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = sim_panel(tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name, table_name = \"panel_data.db\", \"panel_data\"\n",
    "# write to database\n",
    "conn = duckdb.connect(db_name)\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.execute(f\"CREATE TABLE {table_name} AS SELECT * from df\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit  time         Y  W\n",
      "0     0     0  3.096240  0\n",
      "1     0     1  2.656935  0\n",
      "2     0     2  5.084101  0\n",
      "3     0     3  3.274999  0\n",
      "4     0     4  4.638763  0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect(db_name)\n",
    "print(conn.execute(\"SELECT * FROM panel_data LIMIT 5\").fetchdf())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckreg.estimators import DuckMundlak, DuckDoubleDemeaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundlak\n",
    "\n",
    "\n",
    "One-way mundlak \n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "Two-way mundlak\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i, \\cdot} + \\delta \\bar{X}_{\\cdot, t} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "both of which can be compressed easily with `duckdb`.\n",
    "\n",
    "These representations are much more efficient than the above general procedure because the unit and time fixed effects are typically very high dimensional, but covariate averages are not. Also see [Arkhangelsky and Imbens](https://arxiv.org/abs/1807.02099) on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:45<00:00,  5.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.413955</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.896134        0.005633\n",
       "1        1.003877        0.001765\n",
       "2        0.009106        0.009642\n",
       "3       -2.413955        0.002209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mundlak = DuckMundlak(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    covariates=[\"W\"],\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=50,\n",
    "    seed = 929\n",
    ")\n",
    "mundlak.fit()\n",
    "\n",
    "mundlak_results = mundlak.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[mundlak_results[\"point_estimate\"], mundlak_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powered by the following sequence of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE unit_avgs AS\n",
      "        SELECT unit,\n",
      "               AVG(W) AS avg_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "            CREATE TEMP TABLE time_avgs AS\n",
      "            SELECT time,\n",
      "                   AVG(W) AS avg_W_time\n",
      "            FROM panel_data\n",
      "            GROUP BY time\n",
      "            \n",
      "\n",
      "        CREATE TEMP TABLE design_matrix AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W,\n",
      "            u.avg_W_unit\n",
      "            , tm.avg_W_time\n",
      "        FROM panel_data t\n",
      "        JOIN unit_avgs u ON t.unit = u.unit\n",
      "        JOIN time_avgs tm ON t.time = tm.time\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            W,\n",
      "            avg_W_unit\n",
      "            , avg_W_time,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM design_matrix\n",
      "        GROUP BY W,\n",
      "                    avg_W_unit\n",
      "                    , avg_W_time\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                W,\n",
      "                avg_W_unit\n",
      "                , avg_W_time,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM design_matrix\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY W,\n",
      "                        avg_W_unit\n",
      "                        , avg_W_time\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(mundlak.unit_avg_query)\n",
    "print(mundlak.time_avg_query)\n",
    "print(mundlak.design_matrix_query)\n",
    "print(mundlak.compress_query)\n",
    "print(mundlak.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Demeaning\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\ddot{X}_{it} \\beta + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\ddot{X}_{it} = X_{it} - \\bar{X}_{i, \\cdot} - \\bar{X}_{\\cdot, t} + \\bar{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:14<00:00,  6.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.295524        0.003857\n",
       "1        1.003877        0.002097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_demean = DuckDoubleDemeaning(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    treatment_var=\"W\",\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 828\n",
    ")\n",
    "\n",
    "double_demean.fit()\n",
    "\n",
    "dd_results = double_demean.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[dd_results[\"point_estimate\"], dd_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE overall_mean AS\n",
      "        SELECT AVG(W) AS mean_W\n",
      "        FROM panel_data\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE unit_means AS\n",
      "        SELECT unit, AVG(W) AS mean_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE time_means AS\n",
      "        SELECT time, AVG(W) AS mean_W_time\n",
      "        FROM panel_data\n",
      "        GROUP BY time\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE double_demeaned AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W - um.mean_W_unit - tm.mean_W_time + om.mean_W AS ddot_W\n",
      "        FROM panel_data t\n",
      "        JOIN unit_means um ON t.unit = um.unit\n",
      "        JOIN time_means tm ON t.time = tm.time\n",
      "        CROSS JOIN overall_mean om\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            ddot_W,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM double_demeaned\n",
      "        GROUP BY ddot_W\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                ddot_W,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM double_demeaned\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY ddot_W\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(double_demean.overall_mean_query)\n",
    "print(double_demean.unit_mean_query)\n",
    "print(double_demean.time_mean_query)\n",
    "print(double_demean.double_demean_query)\n",
    "print(double_demean.compress_query)\n",
    "print(double_demean.bootstrap_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfixest-pKOwcWPT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
