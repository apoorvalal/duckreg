{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `duckreg`: Out-of-memory regressions with `duckdb`\n",
    "\n",
    "Remember to carefully examine the underlying queries that generate the data; the package merely passes it into `np.linalg.lstsq` to solve the least squares problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"rUo3Ku\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.4.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"rUo3Ku\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"rUo3Ku\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"Cm54YG\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.4.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"Cm54YG\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"Cm54YG\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with discrete covariates\n",
    "\n",
    "The largest gains from compression arise when the right hand side variables are discrete, which is also the setting where linearity is an innocuous assumption (especially when the RHS is saturated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
=======
    "# Generate sample data\n",
    "def generate_sample_data(N=10_000_000, seed=12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    X = rng.choice(range(20), (N, 2), True)\n",
    "    Y = D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    Y2 = -1 * D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, Y2, D, X], axis=1), columns=[\"Y\", \"Y2\", \"D\", \"f1\", \"f2\"]\n",
    "    ).assign(rowid=range(N))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create and populate DuckDB database\n",
    "def create_duckdb_database(df, db_name=\"large_dataset.db\", table=\"data\"):\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DuckDB database: large_dataset.db\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "df = generate_sample_data()\n",
    "db_name = 'large_dataset.db'\n",
    "create_duckdb_database(df, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dataset. This dataset could be unreasonably large, which prevents the use of conventional in-memory regression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.226866</td>\n",
       "      <td>24.444717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.088713</td>\n",
       "      <td>35.392007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.472292</td>\n",
       "      <td>21.185366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.842856</td>\n",
       "      <td>38.012720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.136978</td>\n",
       "      <td>22.168634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y         Y2    D    f1    f2  rowid\n",
       "0  27.226866  24.444717  1.0  16.0   5.0      0\n",
       "1  35.088713  35.392007  0.0   1.0  17.0      1\n",
       "2  22.472292  21.185366  1.0   6.0   8.0      2\n",
       "3  39.842856  38.012720  0.0   9.0  15.0      3\n",
       "4  23.136978  22.168634  0.0  10.0   6.0      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = 'large_dataset.db'\n",
    "conn = duckdb.connect(db_name)\n",
    "query = \"SELECT * FROM data limit 5\"\n",
    "conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea of compressed representations is to retain the minimal set of sufficient statistics to compute the point estimate and variance-covariance matrix. We first demo the compression query and the resultant dataset manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12479</td>\n",
       "      <td>424131.097168</td>\n",
       "      <td>1.442763e+07</td>\n",
       "      <td>33.987587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12477</td>\n",
       "      <td>424374.332544</td>\n",
       "      <td>1.444647e+07</td>\n",
       "      <td>34.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12584</td>\n",
       "      <td>591366.998910</td>\n",
       "      <td>2.780306e+07</td>\n",
       "      <td>46.993563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12456</td>\n",
       "      <td>236840.357854</td>\n",
       "      <td>4.515681e+06</td>\n",
       "      <td>19.014158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12356</td>\n",
       "      <td>246972.407371</td>\n",
       "      <td>4.948713e+06</td>\n",
       "      <td>19.988055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     D    f1    f2  count          sum_Y      sum_Y_sq     mean_Y\n",
       "0  0.0  18.0   8.0  12479  424131.097168  1.442763e+07  33.987587\n",
       "1  1.0   5.0  14.0  12477  424374.332544  1.444647e+07  34.012530\n",
       "2  1.0  16.0  15.0  12584  591366.998910  2.780306e+07  46.993563\n",
       "3  0.0  15.0   2.0  12456  236840.357854  4.515681e+06  19.014158\n",
       "4  0.0   6.0   7.0  12356  246972.407371  4.948713e+06  19.988055"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"large_dataset.db\"\n",
    "conn = duckdb.connect(db_name)\n",
    "q = \"\"\"\n",
    "        SELECT D, f1, f2, COUNT(*) as count,\n",
    "        SUM(Y) as sum_Y,\n",
    "        SUM(POW(Y, 2)) as sum_Y_sq,\n",
    "        FROM data\n",
    "        GROUP BY D, f1, f2\n",
    "\"\"\"\n",
    "compressed_df = conn.execute(q).fetchdf()\n",
    "conn.close()\n",
    "\n",
    "compressed_df.eval(f\"mean_Y = sum_Y / count\", inplace=True)\n",
    "print(compressed_df.shape)\n",
    "compressed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reduced a 1 million observation dataset to 800 observations. This will speed up estimation dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "$$\n",
    "Y_i + X_i \\beta + \\alpha_i + \\epsilon_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analytic HC1 standard errors\n",
    "\n",
    "The easiest case is linear regression with robust SEs, which can be computed directly from compressed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 125 ms, total: 1.24 s\n",
      "Wall time: 114 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000862\n",
       "1        0.999347        0.000632\n",
       "2        1.000035        0.000055\n",
       "3        2.000067        0.000055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"\",\n",
    "    n_bootstraps=0,\n",
    "    seed=42,\n",
    ")\n",
    "m.fit()\n",
    "m.fit_vcov()\n",
    "results = m.summary()\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the fully disaggregated data implementation (with fixed effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.8 s, sys: 593 ms, total: 9.4 s\n",
      "Wall time: 4.11 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>t value</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coefficient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1580.197207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>1.000586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Estimate  Std. Error      t value  Pr(>|t|)      2.5%     97.5%\n",
       "Coefficient                                                                 \n",
       "D            0.999347    0.000632  1580.197207       0.0  0.998107  1.000586"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m_pf = pf.feols(\"Y ~ D | f1 + f2\", df, vcov = \"hetero\")\n",
    "m_pf.tidy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyfixest with full data takes ~ 40x longer to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 3s, sys: 6.9 s, total: 4min 10s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9993468884183836), np.float64(0.0006324203286037651))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import statsmodels.formula.api as smf\n",
    "m_smf = smf.ols(\"Y ~ D + C(f1) + C(f2)\", df).fit(cov_type=\"HC1\")\n",
    "m_smf.params.loc[\"D\"], m_smf.bse.loc[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full data run in statsmodels takes around 600x longer than the compressed representation in `DuckRegression`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cluster-robust standard errors\n",
    "\n",
    "for clustered data, we will use the cluster bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000569\n",
       "1        0.999347        0.000736\n",
       "2        1.000035        0.000039\n",
       "3        2.000067        0.000037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 42\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying estimator is powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y, SUM(POW(Y, 2)) as sum_Y_sq\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `DuckRegression` class, you can choose to run the model fits via the `pyfixest` package, in which case \n",
    "the `DuckRegression.fit()` will return a `pyfixest` model object and is therefore compatible with the `pyfixest` API (tables, visualisers etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     est1                    est2\n",
      "------------  ---------------------------  ----------------------\n",
      "depvar                             mean_Y                       Y\n",
      "-----------------------------------------------------------------\n",
      "Intercept     -0.000274*** (8e-06.000000)\n",
      "D              0.999347*** (6e-06.000000)  0.999347*** (0.000941)\n",
      "f1             1.000035*** (1e-06.000000)\n",
      "f2             2.000067*** (1e-06.000000)\n",
      "-----------------------------------------------------------------\n",
      "f1                                      -                       x\n",
      "f2                                      -                       x\n",
      "-----------------------------------------------------------------\n",
      "R2                                      -                0.994031\n",
      "S.E. type                             iid                  by: f1\n",
      "Observations                     10000000                10000000\n",
      "-----------------------------------------------------------------\n",
      "Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n",
      "Format of coefficient cell:\n",
      "Coefficient (Std. Error)\n"
     ]
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 42,\n",
    "    fitter = \"feols\"\n",
    ")\n",
    "duckreg_fit = m.fit()\n",
    "\n",
    "feols_fit = pf.feols(\"Y ~ D | f1 + f2\", data = df)\n",
    "pf.etable([duckreg_fit, feols_fit], digits = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run regressions on multiple outcome variables painlessly since we only need to keep track of summary stats; just include all dependent variables on the RHS of the formula. The output of `DuckRegression.fit()` concatenates the results of all regressions into a single table, which can then be sliced to extract the relevant coefficients and SEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'point_estimate': array([-2.73682294e-04, -4.39868205e-04,  9.99347122e-01, -9.99443294e-01,\n",
       "         1.00003536e+00,  1.00006450e+00,  2.00006685e+00,  1.99995671e+00]),\n",
       " 'standard_error': array([6.70325435e-04, 4.15857348e-04, 7.26599979e-04, 4.45407815e-04,\n",
       "        4.67005434e-05, 4.95007891e-05, 3.96508809e-05, 3.66987192e-05])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y + Y2 ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232\n",
    ")\n",
    "\n",
    "m2.fit()\n",
    "print(results := m2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed data contains summary stats on all outcomes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 13,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y2</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>sum_Y2_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "      <th>mean_Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12727</td>\n",
       "      <td>216544.840414</td>\n",
       "      <td>190925.760161</td>\n",
       "      <td>3.697190e+06</td>\n",
       "      <td>2.876925e+06</td>\n",
       "      <td>17.014602</td>\n",
       "      <td>15.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12619</td>\n",
       "      <td>315592.063979</td>\n",
       "      <td>315659.678406</td>\n",
       "      <td>7.905289e+06</td>\n",
       "      <td>7.908705e+06</td>\n",
       "      <td>25.009277</td>\n",
       "      <td>25.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12586</td>\n",
       "      <td>301966.689482</td>\n",
       "      <td>302001.382204</td>\n",
       "      <td>7.257325e+06</td>\n",
       "      <td>7.259209e+06</td>\n",
       "      <td>23.992268</td>\n",
       "      <td>23.995025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12599</td>\n",
       "      <td>340300.406938</td>\n",
       "      <td>340113.795719</td>\n",
       "      <td>9.204282e+06</td>\n",
       "      <td>9.194163e+06</td>\n",
       "      <td>27.010112</td>\n",
       "      <td>26.995301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12452</td>\n",
       "      <td>448405.221116</td>\n",
       "      <td>448468.700029</td>\n",
       "      <td>1.615983e+07</td>\n",
       "      <td>1.616454e+07</td>\n",
       "      <td>36.010699</td>\n",
       "      <td>36.015797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12308</td>\n",
       "      <td>590645.689337</td>\n",
       "      <td>590779.609323</td>\n",
       "      <td>2.835667e+07</td>\n",
       "      <td>2.836954e+07</td>\n",
       "      <td>47.988763</td>\n",
       "      <td>47.999643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12651</td>\n",
       "      <td>215127.852416</td>\n",
       "      <td>189587.011183</td>\n",
       "      <td>3.670741e+06</td>\n",
       "      <td>2.853889e+06</td>\n",
       "      <td>17.004810</td>\n",
       "      <td>14.985931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12464</td>\n",
       "      <td>249416.510286</td>\n",
       "      <td>224266.276987</td>\n",
       "      <td>5.003233e+06</td>\n",
       "      <td>4.047546e+06</td>\n",
       "      <td>20.010952</td>\n",
       "      <td>17.993122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12375</td>\n",
       "      <td>457882.075324</td>\n",
       "      <td>457804.089079</td>\n",
       "      <td>1.695394e+07</td>\n",
       "      <td>1.694838e+07</td>\n",
       "      <td>37.000572</td>\n",
       "      <td>36.994270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12576</td>\n",
       "      <td>477940.222143</td>\n",
       "      <td>452409.682472</td>\n",
       "      <td>1.817623e+07</td>\n",
       "      <td>1.628749e+07</td>\n",
       "      <td>38.004153</td>\n",
       "      <td>35.974052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       D    f1    f2  count          sum_Y         sum_Y2      sum_Y_sq  \\\n",
       "0    1.0  12.0   2.0  12727  216544.840414  190925.760161  3.697190e+06   \n",
       "1    0.0  15.0   5.0  12619  315592.063979  315659.678406  7.905289e+06   \n",
       "2    0.0  14.0   5.0  12586  301966.689482  302001.382204  7.257325e+06   \n",
       "3    0.0  11.0   8.0  12599  340300.406938  340113.795719  9.204282e+06   \n",
       "4    0.0  18.0   9.0  12452  448405.221116  448468.700029  1.615983e+07   \n",
       "..   ...   ...   ...    ...            ...            ...           ...   \n",
       "795  0.0  18.0  15.0  12308  590645.689337  590779.609323  2.835667e+07   \n",
       "796  1.0   6.0   5.0  12651  215127.852416  189587.011183  3.670741e+06   \n",
       "797  1.0  15.0   2.0  12464  249416.510286  224266.276987  5.003233e+06   \n",
       "798  0.0   3.0  17.0  12375  457882.075324  457804.089079  1.695394e+07   \n",
       "799  1.0  19.0   9.0  12576  477940.222143  452409.682472  1.817623e+07   \n",
       "\n",
       "        sum_Y2_sq     mean_Y    mean_Y2  \n",
       "0    2.876925e+06  17.014602  15.001631  \n",
       "1    7.908705e+06  25.009277  25.014635  \n",
       "2    7.259209e+06  23.992268  23.995025  \n",
       "3    9.194163e+06  27.010112  26.995301  \n",
       "4    1.616454e+07  36.010699  36.015797  \n",
       "..            ...        ...        ...  \n",
       "795  2.836954e+07  47.988763  47.999643  \n",
       "796  2.853889e+06  17.004810  14.985931  \n",
       "797  4.047546e+06  20.010952  17.993122  \n",
       "798  1.694838e+07  37.000572  36.994270  \n",
       "799  1.628749e+07  38.004153  35.974052  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 13,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.df_compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output needs some post-processing."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n"
     ]
    },
    {
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept_Y</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept_Y2</th>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y2</th>\n",
       "      <td>-0.999443</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y2</th>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000040</td>\n",
<<<<<<< HEAD
=======
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y2</th>\n",
       "      <td>1.999957</td>\n",
       "      <td>0.000037</td>\n",
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000670\n",
       "1        0.999347        0.000727\n",
       "2        1.000035        0.000047\n",
       "3        2.000067        0.000040"
      ]
     },
     "execution_count": 5,
=======
       "              point_estimate  standard_error\n",
       "Intercept_Y        -0.000274        0.000670\n",
       "Intercept_Y2       -0.000440        0.000416\n",
       "D_Y                 0.999347        0.000727\n",
       "D_Y2               -0.999443        0.000445\n",
       "f1_Y                1.000035        0.000047\n",
       "f1_Y2               1.000064        0.000050\n",
       "f2_Y                2.000067        0.000040\n",
       "f2_Y2               1.999957        0.000037"
      ]
     },
     "execution_count": 14,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
=======
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    "    index = [f\"{x}_{y}\" for x in ['Intercept', \"D\", \"f1\", \"f2\"] for y in ['Y', 'Y2']]\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `DuckRegression` class, you can choose to run the model fits via the `pyfixest` package, in which case \n",
    "the `DuckRegression.fit()` will return a `pyfixest` model object."
=======
    "## Panel Data\n",
    "\n",
    "We have specialised estimators for panel data with N >> T, where the conventional compressed approach is inefficient."
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     est1                    est2\n",
      "------------  ---------------------------  ----------------------\n",
      "depvar                             mean_Y                       Y\n",
      "-----------------------------------------------------------------\n",
      "Intercept     -0.000274*** (8e-06.000000)\n",
      "D              0.999347*** (6e-06.000000)  0.999347*** (0.000941)\n",
      "f1             1.000035*** (1e-06.000000)\n",
      "f2             2.000067*** (1e-06.000000)\n",
      "-----------------------------------------------------------------\n",
      "f1                                      -                       x\n",
      "f2                                      -                       x\n",
      "-----------------------------------------------------------------\n",
      "R2                                      -                0.994031\n",
      "S.E. type                    NP Bootstrap                  by: f1\n",
      "Observations                     10000000                10000000\n",
      "-----------------------------------------------------------------\n",
      "Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n",
      "Format of coefficient cell:\n",
      "Coefficient (Std. Error)\n"
     ]
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name='large_dataset.db',\n",
    "    table_name='data',\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 232,\n",
    "    fitter = \"feols\"\n",
    ")\n",
    "duckreg_fit = m.fit()\n",
    "\n",
    "feols_fit = pf.feols(\"Y ~ D | f1 + f2\", data = df)\n",
    "pf.etable([duckreg_fit, feols_fit], digits = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_panel(\n",
    "    # Parameters\n",
    "    N=1_000_000,\n",
    "    T=35,  # Number of units and time periods\n",
    "    T0=5,  # Treatment starts at T0\n",
    "    tau=0.005,\n",
    "    sigma_list=[5, 2, 0.01, 2],\n",
    "    seed=42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    sigma_unit, sigma_time, sigma_tt, sigma_e = sigma_list\n",
    "    # Generate data\n",
    "    unit_ids = np.repeat(np.arange(N), T)\n",
    "    time_ids = np.tile(np.arange(T), N)\n",
    "\n",
    "    # Generate unit-specific intercepts and time trends\n",
    "    unit_fe = np.random.normal(0, sigma_unit, N)\n",
    "    time_fe = np.random.normal(\n",
    "        0, sigma_time, T\n",
    "    )  # Common shocks for all units at each time period\n",
    "    unit_tt = np.random.normal(0, sigma_tt, N)\n",
    "\n",
    "    # Generate treatment indicator (randomly assigned)\n",
    "    W = np.random.binomial(1, 0.5, N)\n",
    "    W = np.repeat(W, T)\n",
    "    W = W * (time_ids >= T0)\n",
    "\n",
    "    rho = 0.7  # Autoregressive parameter for residuals\n",
    "    # Generate serially correlated residuals for each unit (optimized version)\n",
    "    residuals = np.zeros((N, T))\n",
    "    residuals[:, 0] = np.random.normal(0, sigma_e, N)\n",
    "    epsilon = np.random.normal(0, 1, (N, T - 1))\n",
    "    factor = 0.5 * np.sqrt(1 - rho**2)\n",
    "    for t in range(1, T):\n",
    "        residuals[:, t] = rho * residuals[:, t - 1] + factor * epsilon[:, t - 1]\n",
    "    # iid\n",
    "    # residuals = np.random.normal(0, 0.5, N*T)\n",
    "\n",
    "    # Generate outcome\n",
    "    Y = (\n",
    "        np.repeat(unit_fe, T)\n",
    "        + np.repeat(unit_tt, T) * time_ids\n",
    "        + tau * W  # Treatment effect is 1\n",
    "        + np.tile(time_fe, N)  # time FE\n",
    "        + residuals.flatten()\n",
    "    )  # Individual noise\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"unit\": unit_ids, \"time\": time_ids, \"Y\": Y, \"W\": W})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = sim_panel(tau=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 16,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name, table_name = \"panel_data.db\", \"panel_data\"\n",
    "# write to database\n",
    "conn = duckdb.connect(db_name)\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.execute(f\"CREATE TABLE {table_name} AS SELECT * from df\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit  time         Y  W\n",
      "0     0     0  3.096240  0\n",
      "1     0     1  2.656935  0\n",
      "2     0     2  5.084101  0\n",
      "3     0     3  3.274999  0\n",
      "4     0     4  4.638763  0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect(db_name)\n",
    "print(conn.execute(\"SELECT * FROM panel_data LIMIT 5\").fetchdf())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 18,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckreg.estimators import DuckMundlak, DuckDoubleDemeaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundlak\n",
    "\n",
    "\n",
    "One-way mundlak \n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "Two-way mundlak\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i, \\cdot} + \\delta \\bar{X}_{\\cdot, t} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "both of which can be compressed easily with `duckdb`.\n",
    "\n",
    "These representations are much more efficient than the above general procedure because the unit and time fixed effects are typically very high dimensional, but covariate averages are not. Also see [Arkhangelsky and Imbens](https://arxiv.org/abs/1807.02099) on this."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 19,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 50/50 [04:45<00:00,  5.71s/it]\n"
=======
      "100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n"
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.413955</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.896134        0.005633\n",
       "1        1.003877        0.001765\n",
       "2        0.009106        0.009642\n",
       "3       -2.413955        0.002209"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
=======
     "execution_count": 19,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mundlak = DuckMundlak(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    covariates=[\"W\"],\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=50,\n",
    "    seed = 929\n",
    ")\n",
    "mundlak.fit()\n",
    "\n",
    "mundlak_results = mundlak.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[mundlak_results[\"point_estimate\"], mundlak_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powered by the following sequence of queries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 20,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE unit_avgs AS\n",
      "        SELECT unit,\n",
      "               AVG(W) AS avg_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "            CREATE TEMP TABLE time_avgs AS\n",
      "            SELECT time,\n",
      "                   AVG(W) AS avg_W_time\n",
      "            FROM panel_data\n",
      "            GROUP BY time\n",
      "            \n",
      "\n",
      "        CREATE TEMP TABLE design_matrix AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W,\n",
      "            u.avg_W_unit\n",
      "            , tm.avg_W_time\n",
      "        FROM panel_data t\n",
      "        JOIN unit_avgs u ON t.unit = u.unit\n",
      "        JOIN time_avgs tm ON t.time = tm.time\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            W,\n",
      "            avg_W_unit\n",
      "            , avg_W_time,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM design_matrix\n",
      "        GROUP BY W,\n",
      "                    avg_W_unit\n",
      "                    , avg_W_time\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                W,\n",
      "                avg_W_unit\n",
      "                , avg_W_time,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM design_matrix\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY W,\n",
      "                        avg_W_unit\n",
      "                        , avg_W_time\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(mundlak.unit_avg_query)\n",
    "print(mundlak.time_avg_query)\n",
    "print(mundlak.design_matrix_query)\n",
    "print(mundlak.compress_query)\n",
    "print(mundlak.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Demeaning\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\ddot{X}_{it} \\beta + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\ddot{X}_{it} = X_{it} - \\bar{X}_{i, \\cdot} - \\bar{X}_{\\cdot, t} + \\bar{X}$"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 21,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 100/100 [10:14<00:00,  6.15s/it]\n"
=======
      "100%|██████████| 100/100 [01:51<00:00,  1.12s/it]\n"
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.295524        0.003857\n",
       "1        1.003877        0.002097"
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 21,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_demean = DuckDoubleDemeaning(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    treatment_var=\"W\",\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=100,\n",
    "    seed = 828\n",
    ")\n",
    "\n",
    "double_demean.fit()\n",
    "\n",
    "dd_results = double_demean.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[dd_results[\"point_estimate\"], dd_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 22,
>>>>>>> 5c32902935b3b1515adfb2cab6b83f233db9965d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE overall_mean AS\n",
      "        SELECT AVG(W) AS mean_W\n",
      "        FROM panel_data\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE unit_means AS\n",
      "        SELECT unit, AVG(W) AS mean_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE time_means AS\n",
      "        SELECT time, AVG(W) AS mean_W_time\n",
      "        FROM panel_data\n",
      "        GROUP BY time\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE double_demeaned AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W - um.mean_W_unit - tm.mean_W_time + om.mean_W AS ddot_W\n",
      "        FROM panel_data t\n",
      "        JOIN unit_means um ON t.unit = um.unit\n",
      "        JOIN time_means tm ON t.time = tm.time\n",
      "        CROSS JOIN overall_mean om\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            ddot_W,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM double_demeaned\n",
      "        GROUP BY ddot_W\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                ddot_W,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM double_demeaned\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY ddot_W\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(double_demean.overall_mean_query)\n",
    "print(double_demean.unit_mean_query)\n",
    "print(double_demean.time_mean_query)\n",
    "print(double_demean.double_demean_query)\n",
    "print(double_demean.compress_query)\n",
    "print(double_demean.bootstrap_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfixest-pKOwcWPT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
